{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2479376",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfff5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faaiz/my-projects/osingly-be/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff13ff52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osing</th>\n",
       "      <th>indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iro wis madhang?</td>\n",
       "      <td>Kamu sudah makan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Durung, isun pancen arep madhang nang kene</td>\n",
       "      <td>Belum, aku memang mau makan di sini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Riko arep pesen opo?</td>\n",
       "      <td>Kamu mau pesan apa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aku pesen nasi goreng lan teh anget</td>\n",
       "      <td>Aku pesan nasi goreng dan teh hangat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Riko kelendi kabare?</td>\n",
       "      <td>Bagaimana kabarmu?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        osing  \\\n",
       "0                            Iro wis madhang?   \n",
       "1  Durung, isun pancen arep madhang nang kene   \n",
       "2                        Riko arep pesen opo?   \n",
       "3         Aku pesen nasi goreng lan teh anget   \n",
       "4                        Riko kelendi kabare?   \n",
       "\n",
       "                             indonesian  \n",
       "0                      Kamu sudah makan  \n",
       "1   Belum, aku memang mau makan di sini  \n",
       "2                   Kamu mau pesan apa?  \n",
       "3  Aku pesan nasi goreng dan teh hangat  \n",
       "4                    Bagaimana kabarmu?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/kamus.csv\", quotechar='\"')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8858768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bidirectional = pd.concat([\n",
    "    pd.DataFrame({'src': '>>osing<< ' + df['indonesian'], 'tgt': df['osing']}),\n",
    "    pd.DataFrame({'src': '>>indonesian<< ' + df['osing'], 'tgt': df['indonesian']})\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55aec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df_bidirectional, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226c159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    model_inputs = tokenizer(example['src'], truncation=True, padding='max_length', max_length=64)\n",
    "    labels = tokenizer(example['tgt'], truncation=True, padding='max_length', max_length=64)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e359287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3861/3861 [00:00<00:00, 12609.35 examples/s]\n",
      "Map: 100%|██████████| 429/429 [00:00<00:00, 12349.99 examples/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/Helsinki-NLP/opus-mt-id-en/e71532a9cfa6392e7ac5f725d3c9dc82ff6c5a9701b1a407db6dcc25bf4440ce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1750268097&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDI2ODA5N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9IZWxzaW5raS1OTFAvb3B1cy1tdC1pZC1lbi9lNzE1MzJhOWNmYTYzOTJlN2FjNWY3MjVkM2M5ZGM4MmZmNmM1YTk3MDFiMWE0MDdkYjZkY2MyNWJmNDQ0MGNlP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiJ9XX0_&Signature=LFKEoqCt%7EusP-R7iN16akCS2pnm3OCOPdt%7E%7El7Cqd4Gdurpptgyoy2Cl-XJp2cdTfKw5gFO2IZiCcRGCQUVlM8U3wUY0PU2iJVofbrhgvQDKnwQQQ4fSYJphK9woNIK8CyIZKRxi16KlXEs-WypRUUBvGECKiMR20CWh6JYXu39j-l-gwMBVgfpVFNfM7HSM-zBbiS3dlnwq7yL8AOWalJy1mJjuaOcZszqeEAxzABbgdw1vKwfEI1jniG5AUnse72F3j9cLaHQdUHUVqonmdNcaySNyxKYLeQfTGMLDLybAmj4mY53Bc%7EvL-pGadGrg4d8009v2cQg36kKag6EI-g__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/Helsinki-NLP/opus-mt-id-en/e71532a9cfa6392e7ac5f725d3c9dc82ff6c5a9701b1a407db6dcc25bf4440ce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1750268097&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDI2ODA5N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9IZWxzaW5raS1OTFAvb3B1cy1tdC1pZC1lbi9lNzE1MzJhOWNmYTYzOTJlN2FjNWY3MjVkM2M5ZGM4MmZmNmM1YTk3MDFiMWE0MDdkYjZkY2MyNWJmNDQ0MGNlP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiJ9XX0_&Signature=LFKEoqCt%7EusP-R7iN16akCS2pnm3OCOPdt%7E%7El7Cqd4Gdurpptgyoy2Cl-XJp2cdTfKw5gFO2IZiCcRGCQUVlM8U3wUY0PU2iJVofbrhgvQDKnwQQQ4fSYJphK9woNIK8CyIZKRxi16KlXEs-WypRUUBvGECKiMR20CWh6JYXu39j-l-gwMBVgfpVFNfM7HSM-zBbiS3dlnwq7yL8AOWalJy1mJjuaOcZszqeEAxzABbgdw1vKwfEI1jniG5AUnse72F3j9cLaHQdUHUVqonmdNcaySNyxKYLeQfTGMLDLybAmj4mY53Bc%7EvL-pGadGrg4d8009v2cQg36kKag6EI-g__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = Dataset.from_pandas(train_df).map(tokenize_fn, batched=True)\n",
    "val_dataset = Dataset.from_pandas(val_df).map(tokenize_fn, batched=True)\n",
    "\n",
    "# Load base Marian model\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc8c94c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faaiz/my-projects/osingly-be/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/faaiz/my-projects/osingly-be/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/tmp/ipykernel_90147/1682877898.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "# Training config\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9994e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9660' max='9660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9660/9660 1:54:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.291898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.219548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.180258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.162918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.158777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.152120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.151856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.151311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.150808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.151016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faaiz/my-projects/osingly-be/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[54795]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9660, training_loss=0.09964796182531747, metrics={'train_runtime': 6860.051, 'train_samples_per_second': 5.628, 'train_steps_per_second': 1.408, 'total_flos': 654407934935040.0, 'train_loss': 0.09964796182531747, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8e0fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/osing-translator/tokenizer_config.json',\n",
       " 'models/osing-translator/special_tokens_map.json',\n",
       " 'models/osing-translator/vocab.json',\n",
       " 'models/osing-translator/source.spm',\n",
       " 'models/osing-translator/target.spm',\n",
       " 'models/osing-translator/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"models/osing-translator\")\n",
    "tokenizer.save_pretrained(\"models/osing-translator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666ddcc",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54031eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faaiz/my-projects/osingly-be/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import torch\n",
    "\n",
    "model_path=\"models/osing-translator\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_path)\n",
    "model = MarianMTModel.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbb7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riko kelendi kabare?\n",
      "Riko madhang sego\n",
      "isun arep madhang dhisik?\n",
      "Sopo arane riko?\n",
      "Riko wis madhang saka?\n",
      "Walaupun, Walaupun, Walaupun, Walaupun, Walaupun, Meskipun muda Tawa unsapa.\n"
     ]
    }
   ],
   "source": [
    "def translate(text, lang_tag=\">>osing<< \"):  # or >>indonesia<<\n",
    "    input_text = lang_tag + text\n",
    "    tokens = tokenizer([input_text], return_tensors=\"pt\", padding=True)\n",
    "    output = model.generate(**tokens)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(translate(\"apa kabar?\", \">>osing<<\"))\n",
    "print(translate(\"kamu makan nasi\", \">>osing<<\"))\n",
    "print(translate(\"saya mau makan terlebih dahulu\", \">>osing<<\"))\n",
    "print(translate(\"siapa nama kamu?\", \">>osing<<\"))\n",
    "print(translate(\"kamu sudah makan belum?\"))\n",
    "print(translate(\"Anak yang belum tahu\", \">>indonesian<<\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
